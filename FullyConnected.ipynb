{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from cv2 import imread,cvtColor\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('driver_imgs_list.csv')\n",
    "lst = csv.reader(file)\n",
    "file_list = []\n",
    "for i in lst:\n",
    "    file_list.append(i)\n",
    "file_list.pop(0)\n",
    "w = 240\n",
    "h = 320\n",
    "input_size = w * h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "    img = cv2.imread('train/'+file[1]+'/'+file[2],0)\n",
    "    img = cv2.resize(img,(w,h), interpolation=cv2.INTER_LINEAR)\n",
    "    img = img.astype(np.float32)/255.0\n",
    "    label = int(file[1][1])\n",
    "    return img.reshape([1,-1]),label\n",
    "def show(array):\n",
    "    plt.figure()\n",
    "    plt.imshow(array.reshape([h,w]), cmap=\"gray\")\n",
    "    plt.show()\n",
    "def get_test_batch(batch_size,start):\n",
    "    batch = np.zeros((batch_size,w*h))\n",
    "    k = 0\n",
    "    label = np.zeros((batch_size,10))\n",
    "    for i in range(start,start+batch_size):\n",
    "        try:\n",
    "            batch[k:k+1,:],lab = read_file(file_list[i])\n",
    "        except:\n",
    "            print('aaaaa',i)\n",
    "        label[k,lab] = 1\n",
    "        k+=1\n",
    "    return batch,label\n",
    "def get_batch(batch_size):\n",
    "    j = np.random.randint(0,20788,batch_size)\n",
    "    batch = np.zeros((batch_size,w*h))\n",
    "    k = 0\n",
    "    label = np.zeros((batch_size,10))\n",
    "    for i in j:\n",
    "        batch[k:k+1,:],lab = read_file(file_list[i])\n",
    "        label[k,lab] = 1\n",
    "        k+=1\n",
    "    return batch,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 50000\n",
    "display_step = 200\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_0_size = 10\n",
    "h_1_size =  int ( w * h / 100) \n",
    "h_2_size = int ( w * h / 80) \n",
    "h_3_size = int ( w * h / 50) \n",
    "input_size = w * h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder (dtype=tf.float32,shape=[None, input_size])\n",
    "y = tf.placeholder (dtype=tf.float32,shape=[None, 10])\n",
    "lr = tf.placeholder(dtype=tf.float32,shape=[])\n",
    "dr = tf.placeholder(dtype=tf.float32,shape=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_3 = tf.layers.dense(inputs=x,units=h_3_size,activation=tf.nn.tanh)\n",
    "d_h_3 = tf.nn.dropout(h_3,dr)\n",
    "h_2 = tf.layers.dense(inputs=d_h_3,units=h_2_size,activation=tf.nn.tanh)\n",
    "d_h_2 = tf.nn.dropout(h_2,dr)\n",
    "h_1 = tf.layers.dense(inputs=d_h_2,units=h_1_size,activation=tf.nn.relu)\n",
    "d_h_1 = tf.nn.dropout(h_1,dr)\n",
    "h_0 = tf.layers.dense(inputs=d_h_1,units=10)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=h_0))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "correctPred = tf.equal(tf.argmax(h_0,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.299449 0.1328125\n",
      "2.3009262 0.09375\n",
      "2.2947316 0.1484375\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,30*100):\n",
    "    x_,y_ = get_batch(batch_size)\n",
    "    sess.run(optimizer,feed_dict={x:x_,y:y_,lr:0.001,dr:0.5})\n",
    "    if i % 100 == 0:\n",
    "        x_,y_ = get_batch(batch_size)\n",
    "        l,acc = sess.run([loss,accuracy],feed_dict={x:x_,y:y_,dr:1})\n",
    "        print(l,acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "total_acc = 0\n",
    "for i in range(20760,22423,batch_size):\n",
    "    k += 1\n",
    "    x_,y_ = get_test_batch(batch_size,i)    \n",
    "    l,acc = sess.run([loss,accuracy],feed_dict={x:x_,y:y_,dr:1})\n",
    "    total_acc += acc\n",
    "    print(l,acc)\n",
    "total_acc / k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

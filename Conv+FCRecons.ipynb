{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from cv2 import imread,cvtColor\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('driver_imgs_list.csv')\n",
    "lst = csv.reader(file)\n",
    "file_list = []\n",
    "for i in lst:\n",
    "    file_list.append(i)\n",
    "file_list.pop(0)\n",
    "w = 96\n",
    "h = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "    img = cv2.imread('train/'+file[1]+'/'+file[2],0)\n",
    "    img = cv2.resize(img,(w,h), interpolation=cv2.INTER_LINEAR)\n",
    "    img = img.astype(np.float32)/255.0\n",
    "    label = int(file[1][1])\n",
    "    return img,label\n",
    "def show(array):\n",
    "    plt.figure()\n",
    "    plt.imshow(array.reshape([h,w]), cmap=\"gray\")\n",
    "    plt.show()\n",
    "def get_batch(batch_size):\n",
    "    j = np.random.randint(0,20788,batch_size)\n",
    "    batch = np.zeros((batch_size,h,w,1))\n",
    "    k = 0\n",
    "    label = np.zeros((batch_size,10))\n",
    "    for i in j:\n",
    "        batch[k,:,:,0],lab = read_file(file_list[i])\n",
    "        label[k,lab] = 1\n",
    "        k+=1\n",
    "    return batch,label\n",
    "def get_test_batch(batch_size):\n",
    "    j = np.random.randint(20788,22424,batch_size)\n",
    "    batch = np.zeros((batch_size,h,w,1))\n",
    "    k = 0\n",
    "    label = np.zeros((batch_size,10))\n",
    "    for i in j:\n",
    "        batch[k,:,:,0],lab = read_file(file_list[i])\n",
    "        label[k,lab] = 1\n",
    "        k+=1\n",
    "    return batch,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 500000000\n",
    "lr = 0.0001\n",
    "display_step = 200\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder (dtype=tf.float32,shape=[None, h,w,1])\n",
    "\n",
    "con0 = tf.layers.conv2d(inputs=X,kernel_size=(3,3),filters=16,activation=tf.nn.relu,strides=1,padding='same',kernel_initializer=tf.variance_scaling_initializer)\n",
    "con1 = tf.layers.conv2d(inputs=con0,kernel_size=(3,3),filters=16,activation=tf.nn.relu,strides=1,padding='same',kernel_initializer=tf.variance_scaling_initializer)\n",
    "max1 = tf.layers.max_pooling2d(inputs=con1,pool_size=2,strides=2)\n",
    "#######\n",
    "con2 = tf.layers.conv2d(inputs=max1,kernel_size=(3,3),filters=32,activation=tf.nn.relu,strides=1,padding='same',kernel_initializer=tf.variance_scaling_initializer)\n",
    "con3 = tf.layers.conv2d(inputs=con2,kernel_size=(3,3),filters=32,activation=tf.nn.relu,strides=1,padding='same',kernel_initializer=tf.variance_scaling_initializer)\n",
    "max3 = tf.layers.max_pooling2d(inputs=con3,pool_size=2,strides=2)\n",
    "\n",
    "con4 = tf.layers.conv2d(inputs=max3,kernel_size=(3,3),filters=64,activation=tf.nn.relu,strides=1,padding='same',kernel_initializer=tf.variance_scaling_initializer)\n",
    "con5 = tf.layers.conv2d(inputs=con4,kernel_size=(3,3),filters=64,activation=tf.nn.relu,strides=1,padding='same',kernel_initializer=tf.variance_scaling_initializer)\n",
    "max5 = tf.layers.max_pooling2d(inputs=con5,pool_size=2,strides=2)\n",
    "\n",
    "con6 = tf.layers.conv2d(inputs=max5,kernel_size=(3,3),filters=64,activation=tf.nn.relu,strides=1,padding='same',kernel_initializer=tf.variance_scaling_initializer)\n",
    "con7 = tf.layers.conv2d(inputs=con6,kernel_size=(3,3),filters=64,activation=tf.nn.relu,strides=1,padding='same',kernel_initializer=tf.variance_scaling_initializer)\n",
    "max7 = tf.layers.max_pooling2d(inputs=con7,pool_size=2,strides=2)\n",
    "\n",
    "hidden_layer = tf.reshape(max7,[-1,48*64])\n",
    "y_1 = tf.layers.dense(inputs=hidden_layer,units=5000,activation=tf.nn.relu,kernel_initializer=tf.variance_scaling_initializer)\n",
    "\n",
    "out = tf.layers.dense(inputs=y_1,units=w*h)\n",
    "x = tf.reshape(X,shape=[-1,h*w])\n",
    "#loss = tf.reduce_mean(tf.pow(x - out, 2))\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=x, logits=out))\n",
    "Y = tf.placeholder (dtype=tf.float32,shape=[None, 10])\n",
    "y_11 = tf.layers.dense(inputs=y_1,units=1000,activation=tf.nn.relu,kernel_initializer=tf.variance_scaling_initializer)\n",
    "y_2 = tf.layers.dense(inputs=y_11,units=10)\n",
    "clf_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=y_2))\n",
    "correctPred = tf.equal(tf.argmax(y_2,1), tf.argmax(Y,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))\n",
    "lrr = tf.placeholder(shape=[],dtype=tf.float32)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lrr).minimize(clf_loss)\n",
    "optimizer2 =  tf.train.AdamOptimizer(learning_rate=lrr).minimize(loss)\n",
    "\n",
    "##########################################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "clf_l = []\n",
    "l_l = []\n",
    "learn = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,10001):\n",
    "    # Prepare Data\n",
    "    # Get the next batch of MNIST data (only images are needed, not labels)\n",
    "    batch_x,batch_y = get_batch(64)\n",
    "\n",
    "    # Run optimization op (backprop) and cost op (to get loss value)\n",
    "    if i % 2 == 3:\n",
    "        _, l = sess.run([optimizer, clf_loss], feed_dict={X: batch_x,Y:batch_y,lrr:0.001})\n",
    "        print('Class:',l)\n",
    "        clf_l.append(l)\n",
    "    else:\n",
    "        _, l = sess.run([optimizer2, loss], feed_dict={X: batch_x,Y:batch_y,lrr:learn})\n",
    "        print('Recons:',l)\n",
    "        l_l.append(l)\n",
    "    if i % 10 == 1: \n",
    "        learn *= 0.9\n",
    "        total_acc  =  0\n",
    "        batch_x,batch_y = get_test_batch(16)\n",
    "        img = sess.run(out, feed_dict={X: batch_x,Y:batch_y})\n",
    "        plt.imshow(img[0].reshape(h,w),'gray')\n",
    "        plt.show()\n",
    "total_acc  =  0\n",
    "for i in range(100):\n",
    "        batch_x,batch_y = get_test_batch(16)\n",
    "        l,acc = sess.run([clf_loss,accuracy], feed_dict={X: batch_x,Y:batch_y})\n",
    "        total_acc += acc\n",
    "print('-----------------------------Validation:',total_acc/100)\n",
    "plt.semilogy(l_l,label='Recon Error')\n",
    "plt.semilogy(clf_l,label='Class. Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "img = sess.run(out, feed_dict={X: batch_x,Y:batch_y})\n",
    "plt.imshow(img[0].reshape(h,w),'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acc  =  0\n",
    "for i in range(100):\n",
    "        batch_x,batch_y = get_test_batch(16)\n",
    "        l,acc = sess.run([clf_loss,accuracy], feed_dict={X: batch_x,Y:batch_y})\n",
    "        total_acc += acc\n",
    "print('-----------------------------Validation:',total_acc/100)\n",
    "plt.semilogy(l_l[0:1100],label='Recon Error')\n",
    "plt.semilogy(clf_l[0:1100],label='Class. Error')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "img = sess.run(out, feed_dict={X: batch_x,Y:batch_y})\n",
    "plt.imshow(img[0].reshape(h,w),'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn  = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
